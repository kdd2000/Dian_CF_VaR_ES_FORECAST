This thesis compares traditional econometric models and deep learning methods for forecasting market risk, with a focus on Value-at-Risk (VaR) and Expected Shortfall (ES). Risk forecasting is a core challenge in finance, as institutions must strike a balance between regulatory compliance and minimizing losses.
The analysis covers rolling-window estimators, a range of GARCH models with Normal, Student-t, and empirical distribution (EDF) errors, and LSTM neural networks trained under the FZ0 scoring rule, which jointly evaluates VaR and ES. Daily returns for five major assets; EUR/USD, FTSE100, S&P500, Gold, and Crude Oil; are examined over a 15-year horizon.
Performance is judged along two dimensions. Statistical adequacy is tested with regulatory backtests such as the Dynamic Quantile (DQ) test, while economic efficiency is assessed through the FZ0 loss. This dual evaluation shows that GARCH models with heavy-tailed innovations deliver the most efficient forecasts, particularly for FX and Gold. LSTMs, on the other hand, stand out in meeting coverage requirements, especially at the 5% level. Equities highlight the trade-off: LSTMs provide better regulatory adequacy, whereas GARCH offers lower tail-loss estimates.
The findings suggest that these approaches are not substitutes but complements. GARCH remains valuable for producing loss-efficient forecasts, while LSTMs add robustness in terms of regulatory consistency. Taken together, the results provide useful guidance for both researchers and practitioners working at the intersection of financial econometrics, machine learning, and risk management under Basel III/IV.
Keywords: Value-at-Risk (VaR), Expected Shortfall (ES), Risk Forecasting, GARCH Models, LSTM Neural Networks, FZ0 Loss, Backtesting, Financial Econometrics, Machine Learning, Basel III
<img width="468" height="546" alt="image" src="https://github.com/user-attachments/assets/f7c94b80-251d-44ca-ab7b-ff5d2d5da0de" />
